# Time series

## Conceptos previos

* https://es.wikipedia.org/wiki/Autocorrelaci%C3%B3n
* https://es.wikipedia.org/wiki/Proceso_estoc%C3%A1stico

* Pvalor < 0.05 => rechazo hipÃ³tesis nula (Ho)- 
* Pvalor > 0.05 => acepto Ho. 

Esto es porque todas las hipÃ³tesis se hacen con una confianza de 95% (el 0.05=1-NC es el nivel de significancia, alpha). 

## IntroducciÃ³n

Series de tiempo o temporales en espaÃ±ol. Ya no son de Machine Learning. No hay un aprendizaje. SÃ³lo son estadÃ­sticas y fÃ³rmulas que permiten predecir a un plazo determinado. 

![serie-temporal](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/02/train_test-768x438.png)

Ya no tengo una Y a predecir y varias X. Lo que tengo es una Y(t), donde t es tiempo e Y es la variable a predecir. 

Por tanto:

* Ya no tenemos datos supervisados ni no supervisados.
* No queremos predecir una variable que depende de otras.
* Ahora tenemos una variable que depende Ãºnicamente del tiempo.
* Â¿Podemos utilizar los mismos modelos que aprendimos en los cursos anteriores?

## DefiniciÃ³n 

Una serie tiempo es una secuencia de observaciones, medidos en determinados momentos del tiempo, ordenados cronolÃ³gicamente y, espaciados entre sÃ­ de manera uniforme, asÃ­ los datos usualmente son dependientes entre sÃ­. El principal objetivo de una serie de tiempo ğ‘‹_ğ‘¡  (ğ‘¡=1,â€¦,ğ‘›), es su anÃ¡lisis para hacer pronÃ³stico. 

Son variables **discretas**. 

## Ejemplos de aplicaciÃ³n

### EconomÃ­a y Marketing
* Proyecciones del empleo y desempleo.
* EvoluciÃ³n del Ã­ndice de precios de la leche.
* Beneficios netos mensuales de cierta entidad bancaria.
* Ãndices del precio del petrÃ³leo.

###  DemografÃ­a
* NÃºmero de habitantes por aÃ±o.
* Tasa de mortalidad infantil por aÃ±o.

### Medioambiente
* EvoluciÃ³n horaria de niveles de Ã³xido de azufre y de niveles de Ã³xido de nitrÃ³geno en una ciudad durante una serie de aÃ±os.
* Lluvia recogida diariamente en una localidad.
* Temperatura media mensual.
* MediciÃ³n diaria del contenido en residuos tÃ³xicos en un rÃ­o. 

## Componentes de una serie temporal

El anÃ¡lisis clÃ¡sico de las series temporales se basa en la suposiciÃ³n de que los valores que toma la variable de observaciÃ³n es la consecuencia de tres componentes, cuya actuaciÃ³n conjunta da como resultado los valores medidos, estos componentes son:

### Componente tendencia

Se puede definir como un cambio a **largo plazo** que se produce en la relaciÃ³n al nivel medio, o el cambio a largo plazo de la media. La tendencia se identifica con un movimiento suave de la serie a largo plazo.

### Componente estacional

Muchas series temporales presentan **cierta periodicidad** o dicho de otro modo, variaciÃ³n de cierto perÃ­odo (semestral, mensual, etc.). Estos efectos son fÃ¡ciles de entender y se pueden medir explÃ­citamente o incluso se pueden eliminar de la serie de datos, a este proceso se le llama desestacionalizaciÃ³n de la serie.

### Componente aleatoria

Esta componente **no responde a ningÃºn patrÃ³n de comportamiento**, sino que es el resultado de factores fortuitos o aleatorios que inciden de forma aislada en una serie de tiempo

Por tanto 
> ğ‘‹_ğ‘¡=ğ‘‡_ğ‘¡+ğ¸_ğ‘¡+ğ¼_ğ‘¡

Donde 
* ğ‘‡_ğ‘¡ es la **tendencia**.
* ğ¸_ğ‘¡ es la **componente estacional**.
* ğ¼_ğ‘¡   es la **componente aleatoria**. 

![componentes](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/01/Multiplicative-Decomposition-of-Airline-Passenger-Dataset.png)

## ClasificaciÃ³n descriptiva de las series temporales 

Las series temporales se pueden clasificar en:

### Estacionarias

Una serie es estacionaria cuando es estable a lo largo del tiempo, es decir, cuando la media y varianza son constantes en el tiempo. Esto se refleja grÃ¡ficamente en que los valores de la serie tienden a oscilar alrededor de una media constante y la variabilidad con respecto a esa media tambiÃ©n permanece constante en el tiempo.

Un proceso estocÃ¡stico (estocÃ¡stico=depende del tiempo y tiene componente aleatoria) se dice que es estacionario si

ğ”¼[ğ‘‹_ğ‘¡ ]=ğ”¼[ğ‘‹_(ğ‘¡+ğ‘˜) ]=ğœ‡. Media constante.

ğ‘‰ğ‘ğ‘Ÿ[ğ‘‹_ğ‘¡ ]=ğ‘‰ğ‘ğ‘Ÿ[ğ‘‹_(ğ‘¡+ğ‘˜) ]=ğœ^2. Varianza constante

ğ”¼[ã€–(ğ‘‹ã€—_ğ‘¡âˆ’ğœ‡)(ğ‘‹_(ğ‘¡+ğ‘˜)âˆ’ğœ‡)] (covarianza) no depende del tiempo


### No estacionarias

Son series en las cuales la tendencia y/o variabilidad cambian en el tiempo. Los cambios en la media determinan una tendencia a crecer o decrecer a largo plazo, por lo que la serie no oscila alrededor de un valor constante.

![media_estacionaria](https://estrategiastrading.com/wp-content/uploads/2016/12/media_estacionaria.png)
La serie de la izquierda tiene una media constante, en cambio la figura de la derecha muestra tendencia, y su media se incrementa con el paso del tiempo.

![homoscedasticidad](https://estrategiastrading.com/wp-content/uploads/2016/12/homoscedasticidad.png)
La serie de la derecha no es estacionaria, su varianza se incrementa.

![Autocovarianza](https://estrategiastrading.com/wp-content/uploads/2016/12/autocovarianza.png)

## Cross validation en series de tiempo

La cross validation la usÃ¡bamos 

Cogemos una pequeÃ±a parte de la serie para entrenar y otra pequeÃ±a (contigua, claro) para testear. PequeÃ±a porque las series temporales aciertan sobre todo en tiempos pequeÃ±os, no tiene sentido probar con test muy largo).

Luego voy aumentando el training, dejando la longitud de test igual. 

![image](https://miro.medium.com/max/736/1*5vky1z29e1iO6iOvCTBJxg.png)

Ver (https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9)

# Modelos


## Modelo Autoregresivo AR(p)

Este modelo es muy bonito en teorÃ­a, pero no suele pasar. 

Los modelos autoregresivos se basan en la idea de que el valor actual de la serie ğ‘‹_ğ‘¡, puede explicarse en funciÃ³n de valores pasados ğ‘‹_(ğ‘¡âˆ’1),â€¦,ğ‘‹_(ğ‘¡âˆ’ğ‘), donde ğ‘ determina el nÃºmero de retrasos necesarios para pronosticar un valor actual. El modelo autoregresivo de orden ğ‘ estÃ¡ dado por:

ğ‘‹_ğ‘¡=ğœ™_0+ğœ™_1 ğ‘‹_(ğ‘¡âˆ’1)+â‹¯+ğœ™_ğ‘ ğ‘‹_(ğ‘¡âˆ’ğ‘)+ğœ€_ğ‘¡

Donde ğœ€_ğ‘¡ es un ruido blanco.

Ejemplo de modelo autoregresivo de orden 2 (obviando ruido blanco):

X_(t+1) = ğœ™_1 ğ‘‹_(t) + ğœ™_2 ğ‘‹_(t-1)

En este caso mi coeficiente  *t+1* es ğœ™_1 vceces mi coeficiente *t* + ğœ™_2 veces mi coeficiente *t - 1*

## Modelo autoregresivo de media mÃ³vil ARMA(p,q)

SÃ³lo aplicable paraa series de tiempo estacionarias (con media y varianza constante y covarianza no dependiente del tiempo). Es porque si me media no es constante, cuando yo haga depender mi nueva serie de valores anteriores, el modelo no va a salir bien. 

Es muy probable que una serie de tiempo ğ‘‹_ğ‘¡, tenga caracterÃ­sticas de AR y MA a la vez y, por consiguiente, sea ARMA. Por tanto, ğ‘‹_ğ‘¡  sigue un proceso, en este proceso habrÃ¡ tÃ©rminos autoregresivos y tÃ©rminos de media mÃ³vil.

ğ‘‹_ğ‘¡=ã€–ğœ™_0+ğœ™_1 ğ‘‹_(ğ‘¡âˆ’1)+â‹¯+ğœ™_ğ‘ ğ‘‹_(ğ‘¡âˆ’ğ‘)+ğœƒã€—_0+
ğœƒ_1 ğœ€_(ğ‘¡âˆ’1)+â‹¯+ğœƒ_ğ‘ ğœ€_(ğ‘¡âˆ’ğ‘)+ğœ€_ğ‘¡

Donde ğœ€_ğ‘¡ es un ruido blanco.


## Modelo autoregresivo integrado de media mÃ³vil ARIMA(p,d,q)

TambiÃ©n funciona para no estacionarias. 

Los modelos de series de tiempo analizados hasta ahora se basan en el supuesto de estacionariedad, esto es, la media y la varianza para una serie de tiempo son constantes en el tiempo y la covarianza es invariante en el tiempo. Pero la mayorÃ­a de las series de tiempo no son estacionarias, porque pueden ir cambiando de nivel en el tiempo o sencillamente la varianza no es constante en el tiempo, a este tipo de proceso se les considera *procesos integrados*.

Por consiguiente, se debe diferenciar una serie de tiempo d veces para hacerla estacionaria y luego aplicarla a esta serie diferenciada un modelo ARMA(p,q), se dice que la serie original es ARIMA(p,d,q), es decir, una serie de tiempo autoregresiva integrada de media mÃ³vil. Donde p denota el nÃºmero de tÃ©rminos autoregresivos, d el nÃºmero de veces que la serie debe ser diferenciada para hacerla estacionaria y q el nÃºmero de tÃ©rminos de la media mÃ³vil.

ğ‘‹_ğ‘¡=ã€–ğœ™_0+ğœ™_1 ğ‘‹_(ğ‘¡âˆ’1)^ğ‘‘+â‹¯+ğœ™_ğ‘ ğ‘‹_(ğ‘¡âˆ’ğ‘)^ğ‘‘+ğœƒã€—_0+

ğœƒ_1 ğœ€_(ğ‘¡âˆ’1)^ğ‘‘+â‹¯+ğœƒ_ğ‘ ğœ€_(ğ‘¡âˆ’ğ‘)^ğ‘‘+ğœ€_ğ‘¡


La **construcciÃ³n** de los modelos se lleva de manera iterativa mediante un proceso en el que se puede distinguir cuatro etapas: 

![media](/media/arima.png)

### IdentificaciÃ³n. 

Utilizando los datos ordenados cronolÃ³gicamente se intentara sugerir un modelo que merezca la pena ser investigada. El objetivo es determinar los valores que sean apropiados para reproducir la serie de tiempo. En esta etapa es posible identificar mÃ¡s de un modelo candidato que pueda describir la serie. 

### EstimaciÃ³n.

Considerando el modelo apropiado para la serie de tiempo se realiza inferencia sobre los parÃ¡metros.

### ValidaciÃ³n.

Se realizan contraste de diagnostico para validar si el modelo seleccionado se ajusta a los datos, si no es asÃ­, escoger el prÃ³ximo modelo candidato y repetir los pasos anteriores.

Se usa el AIC para ver si el modelo de serie es mejor. A menor AIC, mejor modelo de serie. 

Los residuos son la diferencia entre valor estimado y valor real. Los residuos deberÃ­an ser normales, es decir, caer en una banda. Un modelo NO ES BUENO si los residuos siguen un patrÃ³n. 

### PredicciÃ³n.

Una vez seleccionado el mejor modelo candidato se pueden hacer pronÃ³sticos en tÃ©rminos probabilÃ­sticos de los valores futuros. 

### Existe en R una funciÃ³n auto-arima que te lo hace

Lo que hay detrÃ¡s de esta funciÃ³n es esto. Lo explica porque en un TFM lo preguntÃ³ y el tÃ­o le dijo que usaba el auto arima sin saber lo que hacÃ­a dentro. 

* Se ajustan cuatro modelos iniciales:
ğ´ğ‘…ğ¼ğ‘€ğ´(0,ğ‘‘,0),
ğ´ğ‘…ğ¼ğ‘€ğ´(2,ğ‘‘,2),
ğ´ğ‘…ğ¼ğ‘€ğ´(1,ğ‘‘,0),
ğ´ğ‘…ğ¼ğ‘€ğ´(0,ğ‘‘,1).
* El mejor modelo (aquel con el AIC mÃ¡s pequeÃ±o) es seleccionado. Le llamaremos â€œmodelo actualâ€.
* Se hacen variaciones sobre el modelo actual:
Variar ğ‘ y/o ğ‘ con valores Â±1

Incluye o no la constante de ğ´ğ‘… en el modelo.

El mejor modelo considerado hasta ahora (ya sea el modelo actual o una de estas variaciones) se convierte en el nuevo modelo actual.

* Se repite el paso 2 (c) hasta que no se pueda encontrar un AIC inferior.

### Contraste de hipÃ³tesis

Estacionariedad de Dickey-Fuller.

* H0: Los residuales del modelo ARIMA son estacionarios
* Ha: Los residuales del modelo ARIMA no son estacionarios

Prueba de independencia de los residuales (Box-Pierce test).

* H0: Los residuales del modelo ARIMA son independientes.
* Ha: Los residuales del modelo ARIMA no son independientes. 

## Exponential smoothing

En el modelo autoregresivo, todas las observaciones tienen el mismo peso. Pero puede ser mÃ¡s sensato agregar un mayor peso a las observaciones mÃ¡s recientes que a las observaciones mÃ¡s viejas. Este es exactamente el concepto detrÃ¡s del simple exponencial smoothing.

ğ‘‹_(ğ‘¡+1)=ğ›¼ğ‘¥_ğ‘¡  +ğ›¼(1âˆ’ğ›¼) ğ‘¥_(ğ‘¡âˆ’1 )+ğ›¼(1âˆ’ğ›¼)^2  ğ‘¥_(ğ‘¡âˆ’2)+â‹¯

Donde 0â‰¤ğ›¼â‰¤1 es el parÃ¡metro de suavizado.

## Holt-Winters

Lo que hace es aplicar el exponential smoothing de las tres componentes T, E e I. 

El mÃ©todo de Holt-Winters comprende la ecuaciÃ³n de pronÃ³stico y tres ecuaciones de suavizado (similar a exponencial smoothing): una para el nivel, otra para la tendencia y otra para el componente estacional, con los correspondientes parÃ¡metros de suavizado. Usamos ğ‘š para denotar la frecuencia de la estacionalidad, es decir, el nÃºmero de estaciones en un aÃ±o. Por ejemplo, para datos trimestrales ğ‘š=4, para datos mensuales ğ‘š=12.

### Aditivo

![aditivo](wintersAditivo.PNG)

### Multiplicativo

![aditivo](wintersMultiplicativo.PNG)
